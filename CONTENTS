This is a package to build robots for wikipedia. Some example robots are 
included. 

=======================================================================
PLEASE DO NOT PLAY WITH THIS PACKAGE. These programs can actually
modify the live wikipedia on the net, and proper wiki-etiquette should
be followed before running it on any of the wikipedia sites.
=======================================================================

To get started on proper usage of the interwiki robot, please refer to:

    http://meta.wikipedia.org/wiki/Interwiki_bot/Getting_started



The contents of the package are:

===  Library routines ===

LICENSE                : a reference to the Python Software Foundation license
wikipedia.py           : The wikipedia library
wikipedia_family.py    : The description of the wikipedia family of wikis.
                         wikipedia.py can work for other families like 
                         wikitravel if this module is copied and adapted for
                         such a family.
config.py              : Configuration module containing all defaults. Do not
                         change these! See below how to change values.
lib_images.py          : Part of the Wikipedia library special for the uploading
logger.py              : A support library logging screen output to a file
titletranslate.py      : rules and tricks to auto-translate wikipage titles
date.py                : Date formats in various languages
translator.py          : various translations (for copy_table.py)
catlib.py              : Library routines written especially to handle
                         category pages and recurse over category contents.
unequal.py             : A few routines coordinating exceptions to the 
                         rule that interwiki-linked pages are equal.
nl-exceptions.dat      : Some more specific exceptions used by unequal.py
gui.py                 : Some GUI elements for solve_disambiguation.py
mediawiki_messages.py  : Access to the various translations of the MediaWiki
                         software interface
sqldump.py             : Routines to extract information from local SQL dump
                         files, like the ones at http://download.wikimedia.org
WdTXMLParser.py        : Used by WdT.py

=== Utilities ===

extract_names.py,      
extract_wikilinks.py   : Two bots to get all linked-to Wikipedia pages from an
                         HTML-file. They differ in their output: extract_names
                         gives bare names (can be used for solve_disambiguation.py,
                         table2wiki.py or windows-chars.py), extract_wikilinks
                         gives them in interwiki-link format (can be used for
                         interwiki.py)
login.py               : Log in to an account on your "home" wikipedia. 
splitwarning.py        : split a treelang.log file into warning files for each
                         separate language. suggestion: Zip the created files up, 
                         put them somewhere on the internet, and send an 
                         announcement of the location on the robot mailinglist.
test.py                : Check whether you are logged in.
xmltest.py             : Read an XML file (e.g. the sax_parse_bug.txt sometimes
                         created by interwiki.py), and if it contains an error,
                         show a stacktrace with the location of the error.

=== Robots ===

brackethttp.py         : a bot replacing a ()-bracketed http: link by an
                         explicit [ ] link to avoid a parser problem.
category.py            : add a category link to all pages mentioned on a page,
                         change or remove category tags
check_extern.py        : check external links to see whether they still exist,
                         have been moved etcetera.
copy_table.py          : copy a table from one wikipedia to another, making
                         automatic translations
imagetransfer.py       : Given a Wikipedia page, check the interwiki links
                         for images, and let the user choose among them for
                         images to upload
interwiki.py           : A robot to check interwiki links on all pages (or
                         a range of pages) of a wikipedia.
pagelist.py            : Starting with one or more pages, spiders the wiki
                         forward as well as backward, and thus can be used to
                         get a list of Wikipedia pages connected to a certain
                         subject.
redirect.py            : Fix double redirects and broken redirects. Note:
                         solve_disambiguation also has functions which treat
                         redirects.
replace.py             : Search articles for a text and replace it by another
                         text. Both text are set in two configurable
                         text files. The bot can either work on a set of given
                         pages or crawl an SQL dump.
saveHTML.py            : ?                       
solve_disambiguation.py: Interactive robot doing disambiguation.
standardize_interwiki.py:A robot that downloads a page, and reformats the 
                         interwiki links in a standard way (i.e. move all
                         of them to the bottom or the top, with the same
                         separator, in the right order).
table2wiki.py          : Semi-automatic converting HTML-tables to wiki-tables.
template.py            : change one template (that is {{...}}) into
                         another
upload.py              : upload an image to Wikipedia
us-states.py           : A robot to add redirects to cities for US state 
                         abbreviations.
warnfile.py            : A robot that parses a warning file created by 
                         interwiki.py on another wikipedia language,
                         and implements the suggested changes without
                         verifying them.
windows_chars.py       : change characters that are not part of Latin-1 into
                         something harmless. It is advisable to do this on
                         Latin-1 Wikipedias before switching to UTF-8.
WdT.py                 : something to retrieve the German 'word of the day'

=== Directories ===

disambiguations        : If you run solve_disambiguation.py with the -primary
                         argument, the bot will save information here
mediawiki-messages     : Information retrieved by mediawiki_messages.py will
                         be stored here.
login-data             : login.py stores your cookies here (Your password won't
                         be stored as plaintext).

More precise information, and a list of the options that are available for
the various programs, are given at the start of the programs' source code files.

You need to have at least python version 2.3 installed on your computer
to be able to run any of the code in this package. Support for older
versions of python is not planned.

Before you run any of the programs, you need to create a file named
user-config.py in your current directory. It needs at least two lines: 
The first line should set your real name; this will be used to identify you
when the robot is making changes, in case you are not logged in. The
second line sets the code of your home language. The file should look like:

===========
username='My name'
mylang='xx'
===========

There are other variables that can be set in the configuration file, please
check config.py for ideas.

After that, you are advised to create a username + password for the bot, and
run login.py. If this is not done, the bot will make its edits under an IP
number rather than a login name, a practice which is not liked by people
checking Recentchanges.

You do not need to "install" this package to be able to make use of
it. You can actually just run it from the directory where you unpacked
it or where you have your copy of the CVS sources.


